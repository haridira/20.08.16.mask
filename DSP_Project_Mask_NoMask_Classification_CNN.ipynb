{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "import cv2\n",
    "from matplotlib import image\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Activation,MaxPooling2D,Dropout\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from math import sqrt\n",
    "from matplotlib import image\n",
    "from keras.layers import GaussianNoise\n",
    "from tensorflow.keras.models import load_model\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praga\\Downloads\\ChromDownloads\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\praga\\Downloads\\ChromDownloads\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Good Images, converting to grayscale and saving separately and Resizing to (300,200) and saving separatley.\n",
    "for filename in listdir('maskImages/good'):   \n",
    "    # load the image\n",
    "    image = Image.open('maskImages/good/' + filename)\n",
    "    gs_image = image.convert(mode='L') #Grayscale\n",
    "    image=image.resize((300,200)) #Resize\n",
    "    # save in jpeg format\n",
    "    gs_image.save('maskImages/goodGrayscale/gray_' + filename)  #Save grayscale images\n",
    "    image.save('maskImages/goodResized/resize_' + filename)    #Save resized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Bad Images, converting to grayscale and saving separately and Resizing to (300,200) and saving separatley.\n",
    "for filename in listdir('maskImages/bad'):\n",
    "    # load the image\n",
    "    image = Image.open('maskImages/bad/' + filename)\n",
    "    gs_image = image.convert(mode='L')   #Grayscale\n",
    "    image=image.resize((300,200))    #Resize\n",
    "    # save in jpeg format\n",
    "    gs_image.save('maskImages/badGrayscale/gray_' + filename)    #Save grayscale images\n",
    "    image.save('maskImages/badResized/resize_' + filename)       #Save resized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all images in a directory for good resized\n",
    "loaded_images_resized_good = list()\n",
    "for filename in listdir('maskImages/goodResized'):\n",
    "    # load image\n",
    "    img_data = image.imread('maskImages/goodResized/' + filename)\n",
    "    \n",
    "    # store loaded image\n",
    "    loaded_images_resized_good.append([img_data,\"good\"])\n",
    "    #print('> loaded %s %s' % (filename, img_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all images in a directory for bad resized\n",
    "loaded_images_resized_bad = list()\n",
    "for filename in listdir('maskImages/badResized'):\n",
    "    # load image\n",
    "    img_data = image.imread('maskImages/badResized/' + filename)\n",
    "    # store loaded image\n",
    "    loaded_images_resized_bad.append([img_data,\"bad\"])\n",
    "   # print('> loaded %s %s' % (filename, img_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all images in a directory for good grayscale\n",
    "loaded_images_gray_good = list()\n",
    "for filename in listdir('maskImages/goodGrayscale'):\n",
    "    # load image\n",
    "    img_data = image.imread('maskImages/goodGrayscale/' + filename)\n",
    "    # store loaded image\n",
    "    loaded_images_gray_good.append([img_data,\"good\"])\n",
    "    #print('> loaded %s %s' % (filename, img_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all images in a directory for bad grayscale\n",
    "loaded_images_gray_bad = list()\n",
    "for filename in listdir('maskImages/badGrayscale'):\n",
    "    # load image\n",
    "    img_data = image.imread('maskImages/badGrayscale/' + filename)\n",
    "    # store loaded image\n",
    "    loaded_images_gray_bad.append([img_data,\"bad\"])\n",
    "   # print('> loaded %s %s' % (filename, img_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding labels to the images as \"good\" for proper masked images and \"bad\" otherwise.\n",
    "#Creating dataframe from the images and appending to form one dataframe for all images.\n",
    "bad_im_df = pd.DataFrame(loaded_images_resized_bad)\n",
    "bad_im_df.columns = [\"Mask_Data\",\"Label\"]\n",
    "good_im_df = pd.DataFrame(loaded_images_resized_good)\n",
    "good_im_df.columns = [\"Mask_Data\",\"Label\"]\n",
    "df = good_im_df.append(bad_im_df,ignore_index=True)\n",
    "df.columns = ['Mask_Data','Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Verifying the count of good and bad images\n",
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grayscaled images dataframe creation\n",
    "#Adding labels to the images as \"good\" for proper masked images and \"bad\" otherwise.\n",
    "#Creating dataframe from the images and appending to form one dataframe for all images.\n",
    "bad_im_df_gray = pd.DataFrame(loaded_images_gray_bad)\n",
    "bad_im_df_gray.columns = [\"Mask_Data\",\"Label\"]\n",
    "good_im_df_gray = pd.DataFrame(loaded_images_gray_good)\n",
    "good_im_df_gray.columns = [\"Mask_Data\",\"Label\"]\n",
    "df_gray = good_im_df_gray.append(bad_im_df_gray,ignore_index=True)\n",
    "df_gray.columns = ['Mask_Data','Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data using Stratified shuffle split in 80:20 ratio, test set being 20%.\n",
    "Keeping random state 42 to make the results reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=6,test_size = 0.2,random_state = 42)\n",
    "for train_idx,test_idx in split.split(df,df[\"Label\"]):\n",
    "    train_var = df.iloc[train_idx]\n",
    "    test_var = df.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For grayscale images\n",
    "for train_idx,test_idx in split.split(df_gray,df_gray[\"Label\"]):\n",
    "    train_var_g = df_gray.iloc[train_idx]\n",
    "    test_var_g = df_gray.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Validation set with 20% validation data using stratified split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split(train_var[\"Mask_Data\"],train_var[\"Label\"],test_size=0.2,random_state=42)\n",
    "print(X_train.shape,X_val.shape,y_train.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1260,) (316,) (1260,) (316,)\n"
     ]
    }
   ],
   "source": [
    "#For grayscale images\n",
    "X_train_g,X_val_g,y_train_g,y_val_g = train_test_split(train_var_g[\"Mask_Data\"],train_var_g[\"Label\"],test_size=0.2,random_state=42)\n",
    "print(X_train_g.shape,X_val_g.shape,y_train_g.shape,y_val_g.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting Numerical labels into Categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat=[0]*len(y_train)\n",
    "for i in range (0,len(y_train)):\n",
    "    if y_train.iloc[i] == \"good\":\n",
    "        y_train_cat[i]=[1];\n",
    "    elif y_train.iloc[i] == \"bad\":\n",
    "        y_train_cat[i]=[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Grayscale images\n",
    "y_train_cat_g=[0]*len(y_train_g)\n",
    "for i in range (0,len(y_train_g)):\n",
    "    if y_train_g.iloc[i] == \"good\":\n",
    "        y_train_cat_g[i]=[1];\n",
    "    elif y_train_g.iloc[i] == \"bad\":\n",
    "        y_train_cat_g[i]=[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_cat=[0]*len(y_val)\n",
    "for i in range (0,len(y_val)):\n",
    "    if y_val.iloc[i] == \"good\":\n",
    "        y_val_cat[i]=[1];\n",
    "    elif y_val.iloc[i] == \"bad\":\n",
    "        y_val_cat[i]=[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grayscale images\n",
    "y_val_cat_g=[0]*len(y_val_g)\n",
    "for i in range (0,len(y_val_g)):\n",
    "    if y_val_g.iloc[i] == \"good\":\n",
    "        y_val_cat_g[i]=[1];\n",
    "    elif y_val_g.iloc[i] == \"bad\":\n",
    "        y_val_cat_g[i]=[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting y train into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ar=np.array(y_train_cat)\n",
    "y_val_ar=np.array(y_val_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Grayscale images\n",
    "y_train_ar_g=np.array(y_train_cat_g)\n",
    "y_val_ar_g=np.array(y_val_cat_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Having a look at the image to see if it is decent enough for the model to be trained.\n",
    "plt.imshow(df['Mask_Data'][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the images to 4-D for applying CNN. Using reshape to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lst =[0] * len(X_train) \n",
    "for i in range(0,len(X_train)):\n",
    "    X_train_lst[i] = np.reshape((X_train.iloc[i]),(200,300,3))\n",
    "\n",
    "X_train_ar = np.asarray(X_train_lst)\n",
    "X_train_ar = X_train_ar.astype('float32')\n",
    "X_train_ar /= 255\n",
    "\n",
    "X_val_lst=[0] * len(X_val)\n",
    "for i in range(0,len(X_val)):\n",
    "    X_val_lst[i] = np.reshape((X_val.iloc[i]),(200,300,3))\n",
    "    \n",
    "X_val_ar = np.asarray(X_val_lst)\n",
    "X_val_ar = X_val_ar.astype('float32')\n",
    "X_val_ar /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Grayscale images\n",
    "X_train_lst_g =[0] * len(X_train_g) \n",
    "for i in range(0,len(X_train_g)):\n",
    "    X_train_lst_g[i] = np.reshape((X_train_g.iloc[i]),(1024,1024,1))\n",
    "\n",
    "X_train_ar_g = np.asarray(X_train_lst_g)\n",
    "X_train_ar_g = X_train_ar_g.astype('float32')\n",
    "X_train_ar_g /= 255\n",
    "\n",
    "X_val_lst_g=[0] * len(X_val_g)\n",
    "for i in range(0,len(X_val_g)):\n",
    "    X_val_lst_g[i] = np.reshape((X_val_g.iloc[i]),(1024,1024,1))\n",
    "    \n",
    "X_val_ar_g = np.asarray(X_val_lst_g)\n",
    "X_val_ar_g = X_val_ar_g.astype('float32')\n",
    "X_val_ar_g /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(316, 1024, 1024, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_ar_g.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating and Pre-processing test data by converting it to categorical and then numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data=test_var[\"Mask_Data\"]\n",
    "Y_test_data=test_var[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test_data_g=test_var_g[\"Mask_Data\"]\n",
    "Y_test_data_g=test_var_g[\"Label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting target test set to Categorical Variable and making them numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_cat=[0]*len(Y_test_data)\n",
    "for i in range (0,len(Y_test_data)):\n",
    "    if Y_test_data.iloc[i] == 'good':\n",
    "        Y_test_cat[i]=[1];\n",
    "    elif Y_test_data.iloc[i] == 'bad':\n",
    "        Y_test_cat[i]=[0];\n",
    "\n",
    "Y_test_ar=np.array(Y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For grayscale images\n",
    "Y_test_cat_g=[0]*len(Y_test_data_g)\n",
    "for i in range (0,len(Y_test_data_g)):\n",
    "    if Y_test_data_g.iloc[i] == 'good':\n",
    "        Y_test_cat_g[i]=[1];\n",
    "    elif Y_test_data_g.iloc[i] == 'bad':\n",
    "        Y_test_cat_g[i]=[0];\n",
    "\n",
    "Y_test_ar_g=np.array(Y_test_cat_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting X test data to 4-D and numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_set_cat =[0] * len(X_test_data) \n",
    "for i in range(0,len(X_test_data)):\n",
    "    X_test_set_cat[i] = np.reshape((X_test_data.iloc[i]),(200,300,3))\n",
    "\n",
    "X_test_ar = np.asarray(X_test_set_cat)\n",
    "\n",
    "X_test_ar = X_test_ar.astype('float32')\n",
    "X_test_ar /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For grayscale images\n",
    "X_test_set_cat_g =[0] * len(X_test_data_g) \n",
    "for i in range(0,len(X_test_data_g)):\n",
    "    X_test_set_cat_g[i] = np.reshape((X_test_data_g.iloc[i]),(1024,1024,1))\n",
    "\n",
    "X_test_ar_g = np.asarray(X_test_set_cat_g)\n",
    "\n",
    "X_test_ar_g = X_test_ar_g.astype('float32')\n",
    "X_test_ar_g /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building CNN model with Maxpooling, Dropout and \"relu\" as the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For grayscale images\n",
    "#For grayscale images\n",
    "model_g = Sequential()\n",
    "model_g.add(Conv2D(32, (3, 3), padding='same', input_shape=X_train_ar_g.shape[1:]))\n",
    "model_g.add(GaussianNoise(0.1))\n",
    "model_g.add(Activation('relu'))\n",
    "model_g.add(Conv2D(32, (3, 3)))\n",
    "model_g.add(Activation('relu'))\n",
    "model_g.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_g.add(Dropout(0.25))\n",
    "\n",
    "model_g.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model_g.add(GaussianNoise(0.1))\n",
    "model_g.add(Activation('relu'))\n",
    "model_g.add(Conv2D(64, (3, 3)))\n",
    "model_g.add(Activation('relu'))\n",
    "model_g.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_g.add(Dropout(0.25))\n",
    "\n",
    "model_g.add(Flatten())\n",
    "model_g.add(Dense(50))\n",
    "model_g.add(Activation('relu'))\n",
    "model_g.add(Dropout(0.5))\n",
    "model_g.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model with loss function as \"binary_crossentropy\", since we have binary classification.\n",
    "model_g.compile(loss='binary_crossentropy',metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_accuracy',patience=5, verbose=1, mode='max') #Mode=\"max\" to take weights for maximum accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "315/315 [==============================] - 4197s 13s/step - loss: 2.8046 - accuracy: 0.5127 - val_loss: 0.6937 - val_accuracy: 0.4335\n",
      "Epoch 2/5\n",
      "315/315 [==============================] - 4150s 13s/step - loss: 0.6932 - accuracy: 0.5016 - val_loss: 0.6940 - val_accuracy: 0.4335\n",
      "Epoch 3/5\n",
      "315/315 [==============================] - 4192s 13s/step - loss: 0.6932 - accuracy: 0.5056 - val_loss: 0.6945 - val_accuracy: 0.4335\n",
      "Epoch 4/5\n",
      "315/315 [==============================] - 4221s 13s/step - loss: 0.6932 - accuracy: 0.4913 - val_loss: 0.6949 - val_accuracy: 0.4335\n",
      "Epoch 5/5\n",
      "315/315 [==============================] - 4139s 13s/step - loss: 0.6932 - accuracy: 0.5071 - val_loss: 0.6953 - val_accuracy: 0.4335\n"
     ]
    }
   ],
   "source": [
    "#fitting model\n",
    "Model_g=model_g.fit(X_train_ar_g, y_train_ar_g,\n",
    "              batch_size=4,\n",
    "              epochs=5,\n",
    "              validation_data=(X_val_ar_g, y_val_ar_g),\n",
    "              shuffle=True,callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation accuracy of the model is ~43%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_g.save(r'C:\\Users\\praga\\Downloads\\ChromDownloads\\maskNomaskModelGray.h5') #Saving the grascale model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 1024, 1024, 32)    320       \n",
      "_________________________________________________________________\n",
      "gaussian_noise (GaussianNois (None, 1024, 1024, 32)    0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1024, 1024, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1022, 1022, 32)    9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1022, 1022, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 511, 511, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 511, 511, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 511, 511, 64)      18496     \n",
      "_________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNo (None, 511, 511, 64)      0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 511, 511, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 509, 509, 64)      36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 509, 509, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 254, 254, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 254, 254, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4129024)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                206451250 \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 206,516,293\n",
      "Trainable params: 206,516,293\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model summary\n",
    "model_load_g = load_model(r\"C:\\Users\\praga\\Downloads\\ChromDownloads\\maskNomaskModelGray.h5\")\n",
    "model_load_g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=X_train_ar.shape[1:]))\n",
    "model.add(GaussianNoise(0.1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(GaussianNoise(0.1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Dense(2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_accuracy',patience=5, verbose=1, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#fitting model\n",
    "Model1=model.fit(X_train_ar, y_train_ar,\n",
    "              batch_size=4,\n",
    "              epochs=5,\n",
    "              validation_data=(X_val_ar, y_val_ar),\n",
    "              shuffle=True,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'C:\\Users\\praga\\Downloads\\ChromDownloads\\maskNomaskModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_load = load_model(r\"C:\\Users\\praga\\OneDrive\\Desktop\\mask_recog_ver2.h5\")\n",
    "model_load.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the learning curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(Model1.history['accuracy'], color='red')\n",
    "plt.plot(Model1.history['val_accuracy'],color='green')\n",
    "plt.title('Accuracy plot of training data')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train_set', 'Validation_set'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(Model1.history['loss'], color='red')\n",
    "plt.plot(Model1.history['val_loss'], color='green')\n",
    "plt.title('Loss plot on training data')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train_set', 'Validation_set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the Loss of model on training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model on test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test_ar, Y_test_ar, verbose=True)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred=model.predict_classes(X_test_ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the confusion matrix to see TP, TN, FP and FN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test_ar, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = [0, 1]\n",
    "cm = confusion_matrix(Y_test_ar, y_pred, labels)\n",
    "print(cm)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#from sklearn import ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(Y_test_ar, y_pred, 11='all')\n",
    "cmd = sklearn.metrics.ConfusionMatrixDisplay(cm, display_labels=['mask','noMask'])\n",
    "cmd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Precision and recall scores for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Precision score:%.2f'%precision_score(Y_test_ar, y_pred))\n",
    "print('Recall score:%.2f'%recall_score(Y_test_ar, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying diff model by adding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Conv2D(16, (3, 3), padding='same', input_shape=X_train_ar.shape[1:]))\n",
    "model1.add(GaussianNoise(0.2))\n",
    "model1.add(Activation(\"relu\"))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Conv2D(32, (3, 3), padding='same', input_shape=X_train_ar.shape[1:]))\n",
    "model1.add(GaussianNoise(0.2))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Conv2D(32, (3, 3)))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.5))\n",
    "\n",
    "model1.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model1.add(GaussianNoise(0.1))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Conv2D(64, (3, 3)))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(50))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "#model1.add(Dense(2))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "#model1.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='binary_crossentropy',metrics=['accuracy'])\n",
    "early_stop = EarlyStopping(monitor='val_accuracy',patience=2, verbose=1, mode='max',restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting model\n",
    "Model2=model1.fit(X_train_ar, y_train_ar,\n",
    "              batch_size=4,\n",
    "              epochs=5,\n",
    "              validation_data=(X_val_ar, y_val_ar),\n",
    "              shuffle=True,callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model1.evaluate(X_test_ar, Y_test_ar, verbose=True)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1=model1.predict_classes(X_test_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test_ar, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision and Recall Scores\n",
    "print('Precision score:%.2f'%precision_score(Y_test_ar, y_pred1))\n",
    "print('Recall score:%.2f'%recall_score(Y_test_ar, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = ['mask', 'noMask']\n",
    "cm = confusion_matrix(Y_test_ar, y_pred1, labels)\n",
    "print(cm)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
